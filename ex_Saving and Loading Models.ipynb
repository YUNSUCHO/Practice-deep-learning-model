{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper\n",
    "import fc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, ), (0.5, ))])\n",
    "\n",
    "#download and load the training , test dataset\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download = True, train = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)\n",
    "\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download = True, train = False, transform = transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 231,
       "width": 231
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#here we can see one of the sample\n",
    "image, label = next(iter(trainloader))\n",
    "helper.imshow(image[0,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a network\n",
    "model = fc_model.Network(784, 10, [512, 256, 128])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2..  Training Loss: 1.708..  Test Loss: 1.020..  Test Accuracy: 0.579\n",
      "Epoch: 1/2..  Training Loss: 1.045..  Test Loss: 0.792..  Test Accuracy: 0.719\n",
      "Epoch: 1/2..  Training Loss: 0.896..  Test Loss: 0.680..  Test Accuracy: 0.748\n",
      "Epoch: 1/2..  Training Loss: 0.779..  Test Loss: 0.643..  Test Accuracy: 0.761\n",
      "Epoch: 1/2..  Training Loss: 0.766..  Test Loss: 0.630..  Test Accuracy: 0.760\n",
      "Epoch: 1/2..  Training Loss: 0.715..  Test Loss: 0.616..  Test Accuracy: 0.768\n",
      "Epoch: 1/2..  Training Loss: 0.705..  Test Loss: 0.589..  Test Accuracy: 0.766\n",
      "Epoch: 1/2..  Training Loss: 0.674..  Test Loss: 0.559..  Test Accuracy: 0.791\n",
      "Epoch: 1/2..  Training Loss: 0.668..  Test Loss: 0.551..  Test Accuracy: 0.793\n",
      "Epoch: 1/2..  Training Loss: 0.683..  Test Loss: 0.553..  Test Accuracy: 0.789\n",
      "Epoch: 1/2..  Training Loss: 0.633..  Test Loss: 0.543..  Test Accuracy: 0.796\n",
      "Epoch: 1/2..  Training Loss: 0.661..  Test Loss: 0.535..  Test Accuracy: 0.800\n",
      "Epoch: 1/2..  Training Loss: 0.622..  Test Loss: 0.527..  Test Accuracy: 0.800\n",
      "Epoch: 1/2..  Training Loss: 0.590..  Test Loss: 0.545..  Test Accuracy: 0.791\n",
      "Epoch: 1/2..  Training Loss: 0.611..  Test Loss: 0.540..  Test Accuracy: 0.795\n",
      "Epoch: 1/2..  Training Loss: 0.590..  Test Loss: 0.505..  Test Accuracy: 0.816\n",
      "Epoch: 1/2..  Training Loss: 0.584..  Test Loss: 0.498..  Test Accuracy: 0.812\n",
      "Epoch: 1/2..  Training Loss: 0.583..  Test Loss: 0.494..  Test Accuracy: 0.817\n",
      "Epoch: 1/2..  Training Loss: 0.567..  Test Loss: 0.486..  Test Accuracy: 0.818\n",
      "Epoch: 1/2..  Training Loss: 0.569..  Test Loss: 0.506..  Test Accuracy: 0.815\n",
      "Epoch: 1/2..  Training Loss: 0.567..  Test Loss: 0.500..  Test Accuracy: 0.821\n",
      "Epoch: 1/2..  Training Loss: 0.582..  Test Loss: 0.493..  Test Accuracy: 0.817\n",
      "Epoch: 1/2..  Training Loss: 0.564..  Test Loss: 0.500..  Test Accuracy: 0.810\n",
      "Epoch: 2/2..  Training Loss: 0.586..  Test Loss: 0.496..  Test Accuracy: 0.818\n",
      "Epoch: 2/2..  Training Loss: 0.524..  Test Loss: 0.484..  Test Accuracy: 0.826\n",
      "Epoch: 2/2..  Training Loss: 0.547..  Test Loss: 0.462..  Test Accuracy: 0.830\n",
      "Epoch: 2/2..  Training Loss: 0.529..  Test Loss: 0.482..  Test Accuracy: 0.825\n",
      "Epoch: 2/2..  Training Loss: 0.549..  Test Loss: 0.467..  Test Accuracy: 0.829\n",
      "Epoch: 2/2..  Training Loss: 0.557..  Test Loss: 0.478..  Test Accuracy: 0.825\n",
      "Epoch: 2/2..  Training Loss: 0.556..  Test Loss: 0.466..  Test Accuracy: 0.830\n",
      "Epoch: 2/2..  Training Loss: 0.551..  Test Loss: 0.466..  Test Accuracy: 0.830\n",
      "Epoch: 2/2..  Training Loss: 0.552..  Test Loss: 0.472..  Test Accuracy: 0.834\n",
      "Epoch: 2/2..  Training Loss: 0.562..  Test Loss: 0.466..  Test Accuracy: 0.830\n",
      "Epoch: 2/2..  Training Loss: 0.498..  Test Loss: 0.455..  Test Accuracy: 0.834\n",
      "Epoch: 2/2..  Training Loss: 0.559..  Test Loss: 0.447..  Test Accuracy: 0.840\n",
      "Epoch: 2/2..  Training Loss: 0.520..  Test Loss: 0.457..  Test Accuracy: 0.834\n",
      "Epoch: 2/2..  Training Loss: 0.507..  Test Loss: 0.465..  Test Accuracy: 0.833\n",
      "Epoch: 2/2..  Training Loss: 0.535..  Test Loss: 0.451..  Test Accuracy: 0.836\n",
      "Epoch: 2/2..  Training Loss: 0.521..  Test Loss: 0.451..  Test Accuracy: 0.834\n",
      "Epoch: 2/2..  Training Loss: 0.470..  Test Loss: 0.444..  Test Accuracy: 0.835\n",
      "Epoch: 2/2..  Training Loss: 0.521..  Test Loss: 0.462..  Test Accuracy: 0.833\n",
      "Epoch: 2/2..  Training Loss: 0.505..  Test Loss: 0.459..  Test Accuracy: 0.836\n",
      "Epoch: 2/2..  Training Loss: 0.548..  Test Loss: 0.456..  Test Accuracy: 0.835\n",
      "Epoch: 2/2..  Training Loss: 0.521..  Test Loss: 0.444..  Test Accuracy: 0.836\n",
      "Epoch: 2/2..  Training Loss: 0.497..  Test Loss: 0.440..  Test Accuracy: 0.840\n",
      "Epoch: 2/2..  Training Loss: 0.511..  Test Loss: 0.442..  Test Accuracy: 0.842\n"
     ]
    }
   ],
   "source": [
    "fc_model.train(model, trainloader, testloader, criterion, optimizer, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out model:  Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ") \n",
      "\n",
      "The state dict keys:  odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "#saving and loading network\n",
    "print(\"out model: \", model, \"\\n\")\n",
    "print(\"The state dict keys: \", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('hidden_layers.0.weight', tensor([[-6.9791e-04, -1.1705e-03,  1.4337e-02,  ...,  3.1200e-02,\n",
      "          2.7579e-02,  4.2980e-02],\n",
      "        [-7.5358e-04,  1.6165e-02,  2.6973e-02,  ...,  1.2017e-02,\n",
      "          3.6671e-02,  3.4743e-02],\n",
      "        [ 4.2716e-02,  1.9145e-02,  1.1362e-02,  ...,  1.2866e-02,\n",
      "         -2.7706e-03,  3.3769e-02],\n",
      "        ...,\n",
      "        [ 6.4291e-03,  5.6101e-02,  2.7012e-02,  ...,  3.3353e-02,\n",
      "          3.6795e-02,  2.3278e-02],\n",
      "        [ 1.0439e-02,  3.0693e-02, -1.2624e-02,  ...,  3.5162e-02,\n",
      "         -3.4113e-03, -1.8872e-05],\n",
      "        [-3.2655e-02,  2.5312e-02, -1.6183e-02,  ..., -2.7504e-02,\n",
      "          8.0164e-03,  1.0547e-02]])), ('hidden_layers.0.bias', tensor([-1.4516e-02,  1.5429e-02,  3.5447e-03, -3.8127e-02, -1.1379e-02,\n",
      "         7.2259e-04, -5.8317e-03,  1.4509e-03,  1.3423e-02, -2.7861e-02,\n",
      "        -1.5601e-02,  5.3909e-03, -8.0079e-03,  2.8386e-02, -1.5186e-02,\n",
      "         7.5080e-03, -3.4569e-02, -5.7232e-02, -6.4724e-03,  2.7056e-02,\n",
      "        -4.0403e-02, -4.8137e-02,  9.2965e-03, -3.0638e-02, -4.0791e-02,\n",
      "         6.9491e-03, -9.8754e-04, -2.9283e-02,  2.6789e-03,  2.4760e-02,\n",
      "        -3.2377e-03, -4.6768e-02, -2.8590e-02, -2.9860e-02, -3.6996e-02,\n",
      "        -2.4374e-02,  3.6776e-02, -2.6395e-02,  1.5428e-02, -2.8383e-02,\n",
      "        -1.8737e-02, -5.3626e-02,  2.1008e-02, -3.0441e-02, -4.1889e-02,\n",
      "        -2.0394e-02, -4.7138e-03, -5.7532e-02, -1.3313e-02,  1.2064e-03,\n",
      "        -3.5347e-02, -1.0182e-02,  2.7764e-02, -1.0184e-02, -4.3821e-02,\n",
      "         1.4058e-02, -2.8601e-02, -1.4493e-02,  1.3459e-02, -5.2467e-02,\n",
      "        -2.9978e-02,  1.2430e-02, -2.1540e-02, -4.5096e-02, -2.7465e-02,\n",
      "         8.0959e-03, -3.9299e-02,  1.3631e-02, -2.0747e-02, -1.4392e-02,\n",
      "        -5.3249e-02, -3.7336e-02, -4.1256e-02,  6.7704e-03,  2.9850e-02,\n",
      "        -1.6521e-02, -7.6131e-02, -4.2765e-03,  8.4446e-02, -6.0323e-02,\n",
      "         1.3516e-02, -2.3059e-02,  4.1108e-02, -1.7644e-02,  1.8854e-02,\n",
      "         1.0588e-03,  3.1359e-03, -5.4815e-02, -3.1377e-02,  1.5189e-02,\n",
      "        -2.1413e-02, -2.9474e-02, -4.4107e-02, -5.9349e-03, -4.7714e-02,\n",
      "        -1.0892e-02,  2.1966e-02, -2.9690e-02, -2.4834e-02,  1.9076e-02,\n",
      "        -3.3768e-02,  3.9350e-03, -4.4789e-02, -2.2714e-02, -1.5828e-02,\n",
      "        -2.1897e-02, -2.0262e-02, -3.8762e-02, -4.2122e-02,  1.5755e-02,\n",
      "         2.6314e-03, -9.7008e-03, -2.0821e-02, -3.0712e-02, -2.3923e-02,\n",
      "        -4.2774e-02, -2.7562e-03, -3.1014e-02, -2.8924e-02, -5.3605e-02,\n",
      "         4.4359e-03,  5.0616e-03, -5.7829e-02,  9.9777e-03,  1.3453e-02,\n",
      "         7.7393e-03, -6.6982e-02, -2.5475e-02, -2.2640e-02, -8.0726e-03,\n",
      "        -1.7717e-02, -8.9500e-03, -3.2505e-02, -6.7379e-02, -2.1916e-02,\n",
      "         1.1934e-02, -1.9404e-02,  1.0577e-02, -6.2782e-02, -1.3201e-02,\n",
      "        -1.4464e-02, -1.3379e-02, -4.0516e-03, -1.7995e-03, -3.9100e-02,\n",
      "         3.0453e-02, -3.6900e-02, -3.2955e-02,  1.1784e-02, -1.2809e-02,\n",
      "        -2.7414e-02,  1.5777e-02,  3.6924e-04, -4.6796e-02, -2.6449e-02,\n",
      "        -3.9987e-02, -3.2960e-02,  1.0837e-02, -2.9249e-02, -1.4833e-02,\n",
      "         2.3793e-03, -1.7241e-02,  2.3061e-02, -2.8459e-02,  2.4481e-02,\n",
      "        -1.4230e-02,  1.3184e-02, -4.4292e-02, -3.0129e-02,  2.0539e-02,\n",
      "        -5.4252e-02, -5.1981e-02, -1.5006e-02, -2.7999e-02,  2.9646e-02,\n",
      "         9.4097e-03, -4.2871e-02, -2.6003e-02,  3.3839e-02,  8.9035e-04,\n",
      "        -2.5847e-03, -1.0255e-02, -5.5479e-03,  1.8240e-02,  1.8701e-02,\n",
      "         1.0228e-02,  1.5694e-03,  9.6356e-03, -3.5317e-02, -3.0456e-02,\n",
      "        -4.1718e-02,  8.9761e-03, -4.4121e-02, -2.0953e-02, -7.4648e-03,\n",
      "         9.4804e-03, -7.8017e-02, -2.7237e-03,  1.5986e-04,  6.0418e-04,\n",
      "         1.6803e-03,  3.7338e-03, -3.1651e-02, -4.2977e-02, -6.0624e-02,\n",
      "         1.0391e-02, -1.8871e-02, -4.2968e-02, -1.7799e-02, -1.0440e-02,\n",
      "        -2.3895e-02, -2.4520e-02, -8.5571e-05, -4.1173e-02, -3.5392e-02,\n",
      "        -2.3956e-04,  1.1598e-02, -2.8140e-02, -7.6238e-02, -1.4888e-02,\n",
      "        -2.8780e-02,  3.2235e-04, -3.8518e-02, -1.6476e-02,  4.8171e-02,\n",
      "        -3.8915e-02, -2.8955e-02,  1.2506e-02,  2.5497e-02, -2.8906e-02,\n",
      "         6.6535e-03, -1.5350e-02, -3.0432e-02, -2.8407e-02,  1.0574e-02,\n",
      "         1.4638e-03, -4.4574e-02, -2.0532e-02, -1.4406e-02, -3.2395e-02,\n",
      "         2.5027e-02,  1.7286e-03, -4.3943e-02, -1.8460e-02,  5.2435e-03,\n",
      "        -1.9872e-02, -2.2747e-02, -2.4910e-02,  4.3697e-02, -1.6923e-02,\n",
      "        -5.8281e-02,  7.3041e-03,  4.8473e-03, -1.0845e-03, -4.1856e-02,\n",
      "        -4.0483e-02, -2.5764e-02, -3.6191e-02,  1.3008e-02, -5.9370e-02,\n",
      "        -2.4146e-02, -4.3697e-02, -2.2111e-02,  1.5801e-02, -4.2617e-02,\n",
      "        -9.2040e-03,  8.0462e-03,  1.9676e-02, -1.8590e-02, -1.1476e-02,\n",
      "        -2.5007e-04, -3.7721e-02, -1.3995e-02, -6.4721e-04, -3.6676e-02,\n",
      "        -2.1667e-02, -4.7751e-02,  2.5351e-03, -6.0831e-02, -3.2032e-02,\n",
      "        -1.3338e-03,  2.0938e-02, -1.9882e-02,  1.0915e-02, -4.3378e-02,\n",
      "        -4.9339e-02, -6.0720e-02,  1.2326e-02, -1.0286e-02,  6.7188e-03,\n",
      "        -3.5084e-02,  3.5540e-03, -3.7317e-02, -4.1182e-02, -1.3015e-02,\n",
      "         1.5565e-02,  3.1672e-02,  6.6717e-03, -5.7616e-03,  1.7664e-02,\n",
      "        -5.4723e-02, -2.9272e-02, -4.8023e-02, -4.8765e-03, -2.1585e-02,\n",
      "         1.6500e-02,  2.6471e-02,  2.0801e-02, -1.6501e-02, -4.2809e-02,\n",
      "         1.4306e-02, -2.2979e-02, -4.6955e-02, -3.8034e-02, -4.1812e-02,\n",
      "        -3.1745e-02, -5.1547e-02, -4.5458e-02,  1.4517e-02, -3.7512e-02,\n",
      "         1.0890e-02, -1.2553e-02, -1.7805e-02,  8.6108e-03, -6.9396e-03,\n",
      "        -4.4660e-02, -1.1296e-02, -1.5319e-02, -2.9266e-02,  2.3298e-02,\n",
      "         3.3497e-03,  2.3289e-02, -2.2964e-02, -5.2585e-02,  2.7001e-03,\n",
      "        -1.0514e-02, -3.4967e-02, -3.8009e-02,  1.6000e-02,  2.4925e-02,\n",
      "        -4.0048e-02, -4.8145e-02, -4.0688e-02, -1.6596e-02,  9.3381e-03,\n",
      "        -2.3267e-02,  8.7819e-04,  1.9231e-03,  5.1113e-03, -2.1880e-02,\n",
      "        -6.5987e-03, -2.3635e-02, -3.8747e-02,  4.0376e-03, -6.5503e-03,\n",
      "        -4.0942e-02, -6.0178e-02, -2.3201e-02,  6.4050e-03,  6.4978e-03,\n",
      "         8.7130e-04, -2.9418e-03,  3.4232e-03, -3.6411e-02,  4.5020e-03,\n",
      "        -3.7834e-02,  2.4603e-03, -2.9365e-02, -1.6499e-02, -1.4600e-03,\n",
      "        -3.9160e-02, -1.1379e-02,  1.0113e-02, -3.5462e-03, -2.0030e-02,\n",
      "        -2.9463e-03, -1.9887e-02, -2.0733e-03, -2.4912e-02, -4.4884e-02,\n",
      "        -5.1947e-02, -2.2540e-02, -1.2269e-02, -1.5541e-02,  2.0829e-02,\n",
      "        -1.4318e-02, -2.0860e-02, -5.3164e-02,  1.0211e-03, -1.2967e-02,\n",
      "         1.6349e-02, -4.0708e-02, -2.3228e-02, -1.0594e-02, -2.3340e-02,\n",
      "        -3.0720e-02, -3.9315e-02,  2.8278e-04, -1.2173e-02, -5.9615e-02,\n",
      "         1.1179e-02,  1.5140e-02,  1.2692e-02, -4.5166e-02, -1.8474e-02,\n",
      "        -1.5095e-02, -4.5949e-02,  1.4493e-02, -3.0497e-04, -2.3082e-02,\n",
      "         9.0906e-03, -4.8765e-02, -7.7906e-03, -4.3189e-02,  3.4708e-03,\n",
      "        -8.9636e-03, -1.8907e-02,  3.5497e-02, -9.7985e-03, -9.6643e-03,\n",
      "        -4.8441e-02,  4.3682e-03, -1.3813e-02,  1.9883e-02, -3.2271e-02,\n",
      "        -4.0407e-03, -5.1806e-02,  2.8605e-02, -7.1326e-02,  1.6745e-02,\n",
      "        -4.6151e-02, -1.6038e-02, -5.0943e-02, -3.1815e-02, -1.6613e-02,\n",
      "        -3.7179e-02,  2.7470e-03, -3.0089e-02,  1.3427e-02, -1.6784e-02,\n",
      "        -2.6624e-02, -3.1533e-02, -5.2241e-02, -2.3780e-02,  2.0556e-02,\n",
      "        -1.8720e-02, -6.3451e-02, -2.6128e-02,  7.4994e-03, -5.1949e-02,\n",
      "        -9.8552e-03, -2.9018e-02, -3.7017e-02, -1.3929e-02, -6.8955e-04,\n",
      "        -3.8761e-02,  1.5383e-02, -1.1404e-02,  1.3444e-02, -7.4231e-03,\n",
      "        -3.1620e-02, -2.9543e-03,  1.3370e-02, -1.6603e-02, -1.5116e-02,\n",
      "         2.9631e-02,  2.6797e-02, -1.0788e-02, -3.1109e-02, -2.3804e-03,\n",
      "         3.9121e-03, -6.9544e-03,  1.5619e-02,  8.3530e-03,  2.9002e-02,\n",
      "        -1.8443e-02, -4.6026e-02,  9.3693e-03, -5.9839e-03, -4.1225e-02,\n",
      "        -4.5410e-02,  3.2885e-02,  1.2376e-02, -7.1425e-02, -2.7042e-02,\n",
      "         5.9606e-03, -2.4383e-02,  1.2003e-02, -1.9230e-03, -8.5421e-03,\n",
      "        -1.8295e-02,  1.2551e-03, -3.8079e-02, -1.0476e-02, -6.3351e-03,\n",
      "        -3.5119e-02, -3.6565e-02, -4.9843e-02, -3.6035e-02, -2.1762e-02,\n",
      "        -2.6114e-02, -3.7621e-02, -1.8188e-02, -2.6575e-02, -4.4082e-02,\n",
      "        -2.6901e-02, -6.9581e-02, -4.3647e-03, -5.6728e-02, -2.5136e-02,\n",
      "        -4.8855e-02, -9.9261e-03])), ('hidden_layers.1.weight', tensor([[-0.0159,  0.0205, -0.0299,  ..., -0.0174,  0.0324,  0.0498],\n",
      "        [ 0.0004, -0.0600, -0.0478,  ..., -0.0094, -0.0610, -0.0165],\n",
      "        [ 0.0303,  0.0558,  0.0042,  ...,  0.0269,  0.0292,  0.0671],\n",
      "        ...,\n",
      "        [ 0.0770,  0.0405, -0.0294,  ..., -0.1577,  0.0281,  0.0307],\n",
      "        [-0.0027,  0.0224,  0.0209,  ..., -0.0400, -0.0739,  0.0073],\n",
      "        [-0.0035,  0.0193, -0.0088,  ..., -0.0282,  0.0368, -0.0189]])), ('hidden_layers.1.bias', tensor([ 7.9268e-02,  1.3702e-02, -2.1383e-02, -9.4844e-03,  8.2717e-02,\n",
      "        -8.3608e-03,  5.8916e-02,  2.9218e-02,  2.8743e-02,  5.3127e-02,\n",
      "         3.3094e-02,  6.3976e-02,  8.5528e-03, -4.5663e-02,  9.0149e-02,\n",
      "         1.4565e-02,  1.6016e-02, -1.2168e-02, -4.6763e-02,  1.4427e-02,\n",
      "        -3.3812e-02, -4.3979e-02,  2.5546e-02,  3.2213e-02,  5.4383e-03,\n",
      "         9.7852e-02,  6.6006e-03, -1.2177e-02, -6.2900e-02,  1.1446e-02,\n",
      "         4.3500e-02,  3.0521e-02,  3.7697e-02, -5.4087e-03,  3.4679e-02,\n",
      "         3.6748e-02, -4.5740e-02,  5.9184e-02,  1.1275e-01, -1.2351e-02,\n",
      "        -1.2471e-02,  1.6307e-01, -3.3797e-03, -5.1044e-02,  2.9303e-02,\n",
      "        -1.6453e-02, -5.5975e-02,  4.9958e-02,  1.1468e-02,  3.2021e-03,\n",
      "        -5.5775e-02,  1.5210e-02,  5.4258e-02,  6.5586e-02, -3.2454e-02,\n",
      "        -6.2717e-02, -1.5974e-02,  4.3801e-02,  3.4196e-02,  5.1673e-02,\n",
      "         1.4903e-03, -1.5953e-02, -2.3521e-02, -9.5357e-02,  2.1204e-02,\n",
      "         9.3829e-02,  8.9038e-02,  3.8438e-02,  1.5662e-02,  2.5224e-04,\n",
      "        -3.9343e-03,  3.7736e-02, -4.7333e-02,  5.4627e-03,  2.9586e-02,\n",
      "         6.1859e-02,  7.5146e-02,  2.4153e-02,  9.3357e-02, -4.7956e-02,\n",
      "         1.5399e-02,  3.5869e-02, -1.3993e-02, -4.7689e-02, -1.6571e-02,\n",
      "         4.1111e-02,  4.7851e-02, -2.2973e-02, -8.7437e-03, -4.7487e-02,\n",
      "         3.1915e-02,  5.7327e-03,  1.5868e-03,  2.1714e-02,  2.5590e-02,\n",
      "        -9.0937e-03,  2.0070e-02, -5.6364e-03,  9.1571e-03, -3.3573e-02,\n",
      "         3.1192e-02, -5.8748e-02,  3.5012e-02, -9.9800e-03, -4.9880e-02,\n",
      "        -3.1966e-02, -1.3660e-02,  4.2367e-02,  5.9153e-02,  3.1668e-02,\n",
      "         3.9127e-02, -1.8853e-02,  4.5113e-02, -4.3456e-02, -4.9775e-03,\n",
      "        -4.4260e-02,  2.3151e-02,  6.5228e-04,  1.1451e-02,  3.9791e-02,\n",
      "         4.2982e-02,  1.1159e-01,  2.5964e-02,  3.9171e-02,  8.4638e-02,\n",
      "         6.5955e-02,  1.0893e-02,  2.3775e-02, -1.4534e-02,  5.1061e-02,\n",
      "         6.9289e-02, -7.2895e-02, -8.3146e-03, -9.9804e-03,  3.0182e-02,\n",
      "        -3.3029e-02,  5.4998e-03,  1.1106e-02,  9.1500e-02,  8.5363e-02,\n",
      "         3.3817e-02,  2.0742e-02, -2.2888e-02,  2.3017e-02, -4.3103e-02,\n",
      "        -2.1874e-02,  3.0930e-02,  4.2792e-02,  3.2719e-02, -4.9275e-02,\n",
      "         9.3553e-03, -3.7464e-02,  9.8417e-03,  2.9884e-02, -9.4395e-03,\n",
      "        -3.5057e-02,  5.8668e-02,  5.3355e-02, -3.6780e-02,  1.2649e-02,\n",
      "         7.4591e-02,  4.9295e-02,  4.5464e-02, -4.7178e-02,  3.7708e-02,\n",
      "         6.9352e-03,  4.3690e-02,  3.4573e-02,  6.9729e-03,  1.9909e-02,\n",
      "         1.4699e-02, -6.3887e-02, -1.3512e-03,  3.7311e-03,  5.7079e-03,\n",
      "         3.2996e-02, -7.3659e-03,  4.8422e-02, -4.1607e-05, -4.9268e-02,\n",
      "        -2.2661e-03, -5.4927e-03,  2.1909e-03,  1.9377e-02, -2.9840e-02,\n",
      "         1.4025e-02,  5.3164e-02,  3.7665e-02, -2.0209e-02, -6.0166e-02,\n",
      "         9.2461e-02,  4.6273e-02,  2.6177e-02,  3.6930e-02,  3.8036e-02,\n",
      "         1.6916e-02, -8.4132e-02,  1.8913e-03,  5.1776e-02, -2.3514e-02,\n",
      "         5.4506e-02, -1.0053e-02, -3.5121e-02, -6.2903e-04,  3.1474e-02,\n",
      "         2.9461e-02, -5.8638e-02,  8.8885e-03,  2.2911e-03,  2.2620e-02,\n",
      "        -2.5558e-02,  1.2196e-02,  6.2665e-02, -7.6887e-02,  2.8193e-02,\n",
      "         8.4626e-03,  1.0564e-01,  2.0080e-02,  2.8914e-02,  5.1659e-02,\n",
      "        -2.4486e-03, -6.6509e-03, -8.5825e-02,  5.6108e-02, -5.0504e-02,\n",
      "        -1.0669e-02, -9.5271e-04, -4.8747e-02,  3.1299e-02,  6.8367e-02,\n",
      "         2.3465e-02, -2.8843e-02,  1.5538e-02,  3.0451e-02,  3.0094e-04,\n",
      "         2.1176e-02, -2.0771e-02,  5.5775e-02, -2.5427e-03, -3.6084e-02,\n",
      "        -4.2336e-02,  4.1134e-03,  4.9073e-02,  2.3108e-02, -1.2310e-02,\n",
      "        -1.9420e-02,  2.7451e-02,  5.2298e-03, -9.6637e-02,  8.4337e-02,\n",
      "         2.2362e-02, -1.5007e-02,  2.0633e-02,  5.1500e-02, -2.1660e-03,\n",
      "         2.0097e-02])), ('hidden_layers.2.weight', tensor([[ 0.0581, -0.0714,  0.0736,  ...,  0.0422, -0.0381,  0.0515],\n",
      "        [ 0.0146, -0.0042, -0.0166,  ...,  0.0180, -0.0393, -0.0199],\n",
      "        [-0.0171, -0.0585,  0.0433,  ..., -0.0117,  0.1041,  0.0320],\n",
      "        ...,\n",
      "        [ 0.0268, -0.0029,  0.0706,  ...,  0.0841, -0.0841, -0.0144],\n",
      "        [ 0.0699,  0.0467, -0.0819,  ...,  0.0206, -0.0162, -0.0991],\n",
      "        [-0.0515,  0.0251, -0.0151,  ..., -0.0585, -0.0974,  0.0062]])), ('hidden_layers.2.bias', tensor([ 0.0349,  0.0560,  0.1043,  0.1123, -0.0661,  0.1399, -0.0716,  0.1184,\n",
      "         0.0529,  0.0903, -0.0409,  0.0079,  0.0602,  0.0009,  0.1288, -0.0207,\n",
      "         0.0635,  0.0133,  0.0741,  0.0943,  0.1750,  0.0751,  0.0968, -0.0481,\n",
      "         0.1937, -0.0105,  0.0169,  0.1060,  0.0963,  0.1670,  0.1669,  0.0899,\n",
      "         0.0880,  0.0172,  0.1035,  0.1262,  0.0351,  0.0455,  0.1206,  0.1715,\n",
      "         0.1129,  0.1255,  0.0175, -0.0184,  0.0253,  0.0345, -0.0392,  0.0103,\n",
      "        -0.0054,  0.1610,  0.0268,  0.0109,  0.0681,  0.0866,  0.0558,  0.0275,\n",
      "         0.0754,  0.0313, -0.0453, -0.0045,  0.0422,  0.1158,  0.0579,  0.0048,\n",
      "        -0.0294,  0.0079,  0.0575,  0.1004, -0.0363,  0.0246,  0.0042,  0.0860,\n",
      "        -0.0243,  0.0492,  0.0171,  0.0238,  0.0776,  0.0411,  0.0278,  0.0926,\n",
      "         0.0144, -0.0028,  0.0865, -0.0075,  0.0551,  0.0515,  0.0292, -0.0118,\n",
      "        -0.0703,  0.0628,  0.0638,  0.1192,  0.2219,  0.1115,  0.0517,  0.0122,\n",
      "         0.0871,  0.0396,  0.0166,  0.1244,  0.0986,  0.0647,  0.0686,  0.1015,\n",
      "        -0.0997, -0.0036,  0.0357,  0.0736,  0.0131,  0.0335,  0.1089,  0.1359,\n",
      "         0.1385,  0.1168, -0.0069,  0.0285, -0.0433,  0.0553,  0.0875,  0.1732,\n",
      "         0.0518, -0.0034,  0.0846,  0.0032, -0.0571,  0.1532, -0.0265,  0.0023])), ('output.weight', tensor([[-1.9116e-01,  5.7770e-03,  5.6406e-02,  ...,  1.8969e-02,\n",
      "         -8.0798e-02, -7.2935e-02],\n",
      "        [-8.1536e-02, -5.7764e-02,  9.0058e-02,  ..., -1.1991e-01,\n",
      "          5.7481e-02, -2.4306e-01],\n",
      "        [-1.8936e-01, -1.0473e-01, -9.3344e-02,  ...,  2.3066e-02,\n",
      "         -5.2897e-02, -4.2871e-02],\n",
      "        ...,\n",
      "        [ 5.6952e-02,  1.8307e-02, -2.4279e-01,  ..., -1.0801e-01,\n",
      "          1.3172e-02, -4.2822e-02],\n",
      "        [-2.5103e-02,  5.7575e-02, -3.5418e-02,  ...,  9.0202e-02,\n",
      "          1.1080e-02,  3.0097e-02],\n",
      "        [ 8.7734e-03, -3.3024e-02, -2.0932e-01,  ...,  1.8438e-06,\n",
      "         -7.1512e-02, -2.9120e-02]])), ('output.bias', tensor([-0.1560, -0.2174,  0.0689,  0.0820,  0.0231,  0.0227,  0.1035, -0.0800,\n",
      "         0.0564, -0.0261]))])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = fc_model.Network(checkpoint['input_size'],\n",
    "                             checkpoint['output_size'],\n",
    "                             checkpoint['hidden_layers'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
