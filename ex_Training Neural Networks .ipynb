{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5,), (0.5,)),\n",
    "                               ])\n",
    "#download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download = True, train = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3045, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Build feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10))\n",
    "\n",
    "#Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#get out data\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "#flatten the image\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "\n",
    "#forward pass, get out logits\n",
    "logits = model(images)\n",
    "#calculate loss with the logits and labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3113, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Exercise: Build a model that returns the log-softmax as the output and calculate the loss using the negative log likelihood loss.\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our log-probabilities\n",
    "logps = model(images)\n",
    "# Calculate the loss with the logps and the labels\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.7158,  0.7234],\n",
      "        [-0.1928,  1.0025]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Autograd : automatically calculate the gradients of the tnesor\n",
    "# to use the autograd, need to set requires_grad = True\n",
    "x = torch.randn(2, 2, requires_grad = True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.3755, 0.5233],\n",
      "        [0.0372, 1.0050]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x **2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x121d45358>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2352, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3579,  0.3617],\n",
      "        [-0.0964,  0.5012]])\n",
      "tensor([[-1.3579,  0.3617],\n",
      "        [-0.0964,  0.5012]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#to calculate gradient, need to run .backward()\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss and autograd together\n",
    "#build feedforward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images)\n",
    "loss = criterion(logps, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass:  \n",
      " None\n",
      "After backward pass:  \n",
      " tensor([[ 0.0012,  0.0012,  0.0012,  ...,  0.0012,  0.0012,  0.0012],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0031, -0.0031, -0.0031,  ..., -0.0031, -0.0031, -0.0031],\n",
      "        [ 0.0036,  0.0036,  0.0036,  ...,  0.0036,  0.0036,  0.0036],\n",
      "        [ 0.0003,  0.0003,  0.0003,  ...,  0.0003,  0.0003,  0.0003]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Before backward pass:  \\n\", model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(\"After backward pass:  \\n\", model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the network\n",
    "from torch import optim\n",
    "\n",
    "#optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 0.0308, -0.0195, -0.0037,  ..., -0.0319,  0.0041,  0.0158],\n",
      "        [-0.0152,  0.0056, -0.0356,  ...,  0.0281,  0.0159,  0.0348],\n",
      "        [-0.0221,  0.0226, -0.0072,  ...,  0.0261,  0.0005,  0.0056],\n",
      "        ...,\n",
      "        [-0.0159, -0.0182, -0.0075,  ...,  0.0279, -0.0062, -0.0266],\n",
      "        [ 0.0101, -0.0251,  0.0041,  ...,  0.0110,  0.0125, -0.0234],\n",
      "        [ 0.0321,  0.0058,  0.0260,  ..., -0.0278,  0.0071,  0.0222]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[ 0.0036,  0.0036,  0.0036,  ...,  0.0036,  0.0036,  0.0036],\n",
      "        [-0.0004, -0.0004, -0.0004,  ..., -0.0004, -0.0004, -0.0004],\n",
      "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
      "        ...,\n",
      "        [ 0.0015,  0.0015,  0.0015,  ...,  0.0015,  0.0015,  0.0015],\n",
      "        [ 0.0021,  0.0021,  0.0021,  ...,  0.0021,  0.0021,  0.0021],\n",
      "        [-0.0021, -0.0021, -0.0021,  ..., -0.0021, -0.0021, -0.0021]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient -', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update model:  Parameter containing:\n",
      "tensor([[ 0.0307, -0.0195, -0.0037,  ..., -0.0319,  0.0041,  0.0158],\n",
      "        [-0.0152,  0.0056, -0.0356,  ...,  0.0281,  0.0159,  0.0348],\n",
      "        [-0.0222,  0.0226, -0.0072,  ...,  0.0261,  0.0005,  0.0056],\n",
      "        ...,\n",
      "        [-0.0159, -0.0182, -0.0075,  ...,  0.0279, -0.0062, -0.0266],\n",
      "        [ 0.0101, -0.0251,  0.0041,  ...,  0.0110,  0.0124, -0.0235],\n",
      "        [ 0.0321,  0.0058,  0.0260,  ..., -0.0278,  0.0071,  0.0222]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#take update step and few new weigths()\n",
    "optimizer.step()\n",
    "print(\"Update model: \", model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9734340493104605\n",
      "Training loss: 0.8776459589060436\n",
      "Training loss: 0.5415091214816707\n",
      "Training loss: 0.4421168570039369\n",
      "Training loss: 0.3917290117186524\n"
     ]
    }
   ],
   "source": [
    "#training for real\n",
    "#Exercise: Implement the training pass for our network. \n",
    "#If you implemented it correctly, you should see the training loss drop with each epoch.\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10),\n",
    "                     nn.LogSoftmax(dim = 1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.003)\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        #flatten MNOST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        #training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "#turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "    \n",
    "#output of the network are log_probalilities, need to take experimential for probalilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
